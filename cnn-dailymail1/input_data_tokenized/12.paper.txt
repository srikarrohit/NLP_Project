
\ noindent The unification of low-level perception and high-level reasoning is a long-standing problem in artificial intelligence , which has the potential to not only bring the areas of logic and learning closer together but also demonstrate how abstract concepts might emerge from sensory data . Precisely because deep learning methods dominate perception-based learning , including vision , speech , and linguistic grammar , there is fast-growing literature on how to integrate symbolic reasoning and deep learning . Efforts have ranged from providing a truth-theory to deep learning ~ -LCB- serafini2016logic , garcez2012neural -RCB- , neural architectures that enable differential computation for symbolic constraints ~ -LCB- semanticLossXu2018 , bovsnjak2017programming , rocktaschel2017end , santoro2017simple -RCB- ,
and embeddings for graph and relational data ~ -LCB- yang2014joint , lin2015learning , niepert2016learning , dumancic2018auto -RCB- .
Approaches such as DeepProbLog ~ -LCB- manhaeve2018deepproblog -RCB- , on the other hand , treat deep learning as an external computation and integrate its predictions as an external predicate in a probabilistic logic programming framework . Broadly , efforts seem to fall into three camps : those focused on \ textit -LCB- semantic characterizations -RCB- -LRB- i.e. , define a logic whose formulas capture deep learning -RRB- , \ textit -LCB- constrained learning -RCB- -LRB- i.e. , integrate symbolic constraints in deep learning -RRB- , and \ textit -LCB- hybrid methods -RCB- -LRB- allow neural computations and symbolic reasoning to co-exist separately , to enjoy the strengths of both worlds -RRB- .

In this paper , we identify another dimension to this inquiry : \ textit -LCB- what do the hidden layers really capture , and how can we reason about that logically ? -RCB- In particular , we consider autoencoders -LRB- AEs -RRB- ~ -LCB- goodfellow2016deep , kingma2013auto , rezende2014stochastic -RCB- . As a variant of neural networks , AE frameworks are perhaps the most popular for dimensionality reduction , but its inner workings are entirely opaque and mysterious . Basically , given an encoder \ encoder , one first applies it to input data $ x $ to obtain a feature layer -LRB- \ fl -RRB- and then attempts to recover $ x $ from \ fl ~ using a decoder \ decoder . Constraints on \ fl ~ can lead to massive reductions on the dimensionality and identify salient features for applications such as anomaly detection . -LRB- See , for example , ~ -LCB- dumancic2018auto -RCB- that is a purely logical approach inspired by autoencoding principles . -RRB- Thus , we ask the question : \ textit -LCB- can we inject a logical language onto the \ fl ~ to perform Boolean reasoning over the \ fl 's variables ? -RCB-

The exact choice of the language would depend on what we intend to do with the logic . A purely discrete representation such as propositional logic may not be very interesting or insightful about what the \ fl ~ really captures , especially in cases where there may be probabilities assigned to image labels . In that regard , there has been an interesting development in knowledge representation over the last few years . As a special case of probabilistic logical models ~ -LCB- de2015probabilistic , getoor2007statistical -RCB- tractable probabilistic models have emerged as an extension to data structures such as binary decision diagrams -LRB- BDDs -RRB- . In particular probabilistic sentential decision diagram -LRB- PSDDs -RRB- ~ -LCB- kisa2014probabilistic -RCB- , for example , are a complete and canonical representation of a probabilistic distribution defined over the models of a propositional theory . By imposing certain properties on the propositional representation , such as decomposability and determinism , probabilistic queries can be answered in polynomial time in the size of the data structure by way of model counting . Its parameters can be learned efficiently from data , which allows us to view the representation through a generative lens over a logical base . We discuss below how these features are put to use , but more generally , we see the work as a step in re-purposing deep learning in logical space to contributing to the emergence of high-level reasoning from a low-level system . Our contributions are orthogonal in many regards to the existing literature on neuro-symbolic systems and thus we imagine there would be space for looking at other kinds of integration with the existing literature .

Interestingly , we take note of multiple approaches for visually inspecting and interpreting NNs in the literature ~ -LCB- szegedy2013intriguing , yosinski2015understanding -RCB- , with a special focus on understanding convolutions of deep networks after training ~ -LCB- simonyan2013deep , zeiler2014visualizing -RCB- . While many of these methods yield various analysis of what happens in a given NN , including saliency maps ~ -LCB- simonyan2013deep -RCB- , they differ in thrust significantly from our contributions . For example , optimization methods are usually used to infer and decode regions of interest in a specific layer of a pre-trained network . In contrast to this , our logical approach uses a symbolic framework to make sense of the NN over a generative model . As such we do not infer the meaning of individual variables , although it is possible to visualize them , but rather compute conditional probabilities over those variables .

It should also be noted that recent circuit models attempt to tackle vision problems too -LRB- e.g. , ~ -LCB- poon2011sum , gens2012discriminative , liang2019learning -RCB- -RRB- , and so it is possible to realize the entire image classification pipeline using these tractable probabilistic models -LRB- however usually as a discriminative model -RRB- . We think this is a very exciting development . What our work attempts to do , however , is to inspect state-of-the-art deep learning architectures -LRB- especially models like AEs that are very powerful for dimensionality reduction -RRB- via such symbolic generative models , in case such architectures are already in place , or are tackling problems still to be addressed using a pure circuit scheme . In that regard , as mentioned , our work is to be seen as attempting to re-purpose the latent space in a logical manner .

Our approach offers the following capabilities . We learn a PSDD over a discretized \ fl , which yields a joint distribution over the individual variables , including image labels , of the \ fl. . This allows us , among other things , to visualize these individual variables by conditional sampling . In particular , this enables us to generate example images for a class to get a sense of what was learned . Moreover , the modular structure of the proposed model makes it possible to learn relations over multiple images at a time . Finally , because of the logical structure that we impose , noisy labels can also be handled .
We also discuss how we can evaluate the learned representation over well-known datasets , and also discuss both reconstructability -LRB- i.e. , generative capabilities -RRB- and classification accuracy .
% new paragraph -LRB- not sure if this is not too defensive already -RRB-


At the outset , from an engineering -LRB- as opposed to mathematical -RRB- viewpoint ,
it should be noted that , at this point , since circuit software packages have not enjoyed the same amount of maturity as deep learning packages , the reported accuracy is not as competitive as state-of-the-art systems . Nonetheless , although
% that due to setting a high bar on interpretability in our model , the accuracy reported is sub-par to other state-of-the-art systems when it comes to the classification task . However , while our recorded
this reported accuracy is lower , the model has considerably more functionality , including the ability to sample prototypical images for each of the learned classes , ultimately aiding us in understanding what has been learned by the model -LRB- i.e. , visually showing us what the model thinks a given class represents -RRB- .







@label

The unification of low-level perception and high-level reasoning is a long-standing problem in artificial intelligence , which has the potential to not only bring the areas of logic and learning closer together but also demonstrate how abstract concepts might emerge from sensory data
@label
Precisely because deep learning methods dominate perception-based learning , including vision , speech , and linguistic grammar , there is fast-growing literature on how to integrate symbolic reasoning and deep learning
@label
Broadly , efforts seem to fall into three camps : those focused on defining a logic whose formulas capture deep learning , ones that integrate symbolic constraints in deep learning , and others that allow neural computations and symbolic reasoning to co-exist separately , to enjoy the strengths of both worlds
@label
In this paper , we identify another dimension to this inquiry : what do the hidden layers really capture , and how can we reason about that logically ? In particular , we consider autoencoders that are widely used for dimensionality reduction and inject a symbolic generative framework onto the feature layer
@label
This allows us , among other things , to generate example images for a class to get a sense of what was learned
@label
Moreover , the modular structure of the proposed model makes it possible to learn relations over multiple images at a time , as well as handle noisy labels
@label
Our empirical evaluations show the promise of this inquiry
@label


