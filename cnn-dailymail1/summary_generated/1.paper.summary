 heuristic forward search is currently the dominant paradigm . in classical planning . forward search algorithms typically .
 rely on a single , relatively simple variation of best-first search . and remain fixed throughout the process of solving a planning problem . 
 existing work combining multiple search techniques usually aims at supporting best-first search with an . 
 additional exploratory mechanism , triggered using a handcrafted criterion . a notable exception is very recent work . 
 which combines various search techniques using a trainable . policy . it is , however , confined to a discrete action space comprising several fixed subroutines . 
 in this paper , we introduce a parametrized search algorithm . template which combines various search techniques within . a single routine .
 the template 's parameter space defines an . infinite space of search algorithms , including , among others , . bfs , local and random search . 
 we further introduce a neural . architecture for designating the values of the search parameters given the state of the search . 
 this enables expressing neural search policies that change the values of the parameters as . the search progresses .
 the policies can be learned automatically , with the objective of maximizing the planner 's performance on a given distribution of planning problems . 
 we . consider a training setting based on a stochastic optimization . algorithm known as the cross-entropy method -lrb- cem -rrb- .
 experimental evaluation of our approach shows that it is capable of . finding effective distribution-specific search policies , outperforming the relevant baselines .
INFO:tensorflow:GENERATED SUMMARY: